{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-31T09:40:07.287248100Z",
     "start_time": "2025-05-31T09:40:02.711409700Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~atplotlib (c:\\Users\\m\\projects\\tech-summit\\.venv\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~atplotlib (c:\\Users\\m\\projects\\tech-summit\\.venv\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~atplotlib (c:\\Users\\m\\projects\\tech-summit\\.venv\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~atplotlib (c:\\Users\\m\\projects\\tech-summit\\.venv\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "%pip install --quiet python-dotenv openai langchain_community pgvector psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "feae7ec94588295b",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import PGVector\n",
    "from langchain_core.documents import Document\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "load_dotenv('../.env')\n",
    "\n",
    "class PGVectorKnowledgeBase:\n",
    "    def __init__(self):\n",
    "        self.text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=20)\n",
    "        self.vectorstore = PGVector(\n",
    "            collection_name='workshop_knowledge_base',\n",
    "            connection_string='postgresql://postgres:postgres@localhost:5432/postgres',\n",
    "            embedding_function=OpenAIEmbeddings(model=\"text-embedding-3-small\", openai_api_key=os.getenv('OPENAI_API_KEY')),\n",
    "        )\n",
    "\n",
    "    def add_txt(self, path_to_txt):\n",
    "        with open(path_to_txt, 'r', encoding='utf-8') as f:\n",
    "            full_text = f.read()\n",
    "        self.vectorstore.add_documents([Document(page_content=chunk) for chunk in self.text_splitter.split_text(full_text)])\n",
    "\n",
    "    def search_with_score(self, query: str, k: int = 3) -> list[tuple[Document, float]]:  # dodany score\n",
    "        return self.vectorstore.similarity_search_with_score(query, k=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ad324b33f1135a0e",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\m\\AppData\\Local\\Temp\\ipykernel_27520\\812249188.py:13: LangChainPendingDeprecationWarning: Please use JSONB instead of JSON for metadata. This change will allow for more efficient querying that involves filtering based on metadata. Please note that filtering operators have been changed when using JSONB metadata to be prefixed with a $ sign to avoid name collisions with columns. If you're using an existing database, you will need to create a db migration for your metadata column to be JSONB and update your queries to use the new operators. \n",
      "  self.vectorstore = PGVector(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "load_dotenv('../.env')\n",
    "client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))\n",
    "\n",
    "knowledge_base = PGVectorKnowledgeBase()\n",
    "\n",
    "def augument(docs_with_score, user_question) -> str:\n",
    "    # Filtracja dokumentów ze zbyt niskim scorem\n",
    "    docs_filtered_by_score = [(doc, score) for doc, score in docs_with_score if score > 0.5]\n",
    "    \n",
    "    # Formatowanie dokumentów do wyświetlenia\n",
    "    docs_formatted = \"\\n\".join([f\"Document: {doc.page_content} Score: {score}\" for doc, score in docs_filtered_by_score])\n",
    "    system_prompt = \"Jesteś pomocnym asystentem. Odpowiedź zwięźle i na temat TYLKO na bazie podanego kontekstu\\n\"\n",
    "    user_prompt = (f\"kontekst z miarą podobieństwa do pytania użytkownika: {docs_formatted}\\n\"\n",
    "                          f\"pytanie użytkownika: {user_question}\")\n",
    "    return system_prompt, user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8ce507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Podczas warsztatów będziesz budować AI chatbota z wykorzystaniem techniki RAG, łącząc modele językowe z danymi zewnętrznymi. Dowiesz się, jak przygotować dane do użytku przez bota, stworzysz działającego chatbota i zintegrujesz wszystko w prostym projekcie. Warto wiedzieć, że potrzebna jest znajomość podstaw Pythona oraz laptop z Pythonem i IDE, np. VSCode lub PyCharm.'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def chat_with_model(user_question: str) -> str:\n",
    "    # Faza Retreive, szukanie dokumentów w bazie wiedzy na podstawie pytania użytkownika\n",
    "    docs_with_score = knowledge_base.search_with_score(user_question)\n",
    "\n",
    "    # Faza Augument\n",
    "    system_prompt, user_prompt = augument(docs_with_score, user_question)\n",
    "\n",
    "    # Faza Generate, wysłanie zapytania do modelu\n",
    "    response = client.chat.completions.create(\n",
    "        model='gpt-3.5-turbo',\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt},\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96de75db",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_with_model(\"powiedz jaka jest agenda warsztatów\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
